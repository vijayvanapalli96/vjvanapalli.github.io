

## KAGGLE COMPETITION

## Introduction 

In this blog post we will be exploring different methods to explore the growth of objects, or the changes that appear in them over time. 

This post will mainly try to explore these changes through two methods:

1. Segment Anything
2. Preprocessing each frame to highlight the objects on the video, and performing contour detection

## Segment Anything 

We can take a look at the masks generated by Segment Anything on the original video side by side. 
While the mask generated is useful, getting the area of the mask is tedious as it involves concatenating the masks points sequentially, identifying as a contour and calculating the area.


![output (1)](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/84d8e6a4-6057-42d4-89b1-a02f950ad264)

We perform similar mask segmenation to see how accurately it outlines the flowers 

![output (2)](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/d17cb4b3-4106-4cba-9c9f-fee01636de89)

It looks like the SAM basically isolates the foreground object and applies a red tint mask to the black background

The issues faced are as follows:
1. Processing a single video takes a lot of time and resources
2. Calculating the area under a mask requires more data manipulation, employing cv2 functions to find the area enclosed within a changing polygon that may get disjointed. 
   
## Preprocessing Images

This process proved to be less computationally intensive.
For the same video, I thresholded the image, and used cv2s findContour function to isolate the foreground object from the blank background. The contrasting colors and the high definition video allowed me to not account of any occlusion or noise. 
The results can be seen below

![output (4)](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/800c4607-5cd2-4d78-93ab-893708316130)





Similarly we can extend this way of measuring growth to other objects. 
Crystallization is an interesting problem domain, while we can't measure the actual mass of the crystal we can at least measure the rate of growth if given the duration for which the time lapse has occured as shown below. 




![ezgif-5-91bd283579](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/e5b83066-0ac1-4b9e-b0f0-0bb63be993e5)
<img width="329" alt="image" src="https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/2d99025c-937d-4d44-a65b-ac5b5e8909e4">

(Please wait a few seconds as the time lapse is a little long)


In the dandelion video the area change is quite significantly measured, and thus allows us to calculate growth rate.
We can apply similar constraints 
## Analysis of Results 

For the blue flower we can observe the following results, which is consistent with what we see, the growth rate does not really change much during the duration of the video after the initial spike which means we're looking at a consistent growth rate, or there isn't much noticible change


![blueoutput](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/7d32e04f-d856-4fc3-a983-0447407d5926)<img width="304" alt="image" src="https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/1fed2127-061b-46e6-a64a-3eb78df7dff2">

I tried to extend this analysis to other types of flowers as well :

![ezgif-3-e762fdcb63](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/d81ce803-01a6-4a45-9f6b-8314ba378fab)<img width="338" alt="image" src="https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/6f88c86f-c599-42c8-af57-a080f49852e0">


![output (8)](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/3a721c9e-046a-4f9a-98a4-93ae09232cc4)<img width="314" alt="image" src="https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/f1c00258-c2e3-4c9a-8c5f-893420fdd833">



![output (9) (1)](https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/5ceacf88-5c5a-42b9-9720-27f73a5ac60c)<img width="332" alt="image" src="https://github.com/vijayvanapalli96/vjvanapalli.github.io/assets/46009628/724e02f3-cff3-4a7a-b4b6-fbec247c9248">




## Code breakdown and Conclusion
1. For Contour detection

```
def process_frame(frame):
    global prev_total_area

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    total_area = 0

    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 100:
            cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)
            total_area += area

    growth_rate = (total_area - prev_total_area) 
    cv2.putText(frame, f"Total Area: {total_area}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(frame, f"Growth Rate: {growth_rate} pixels/sec", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    prev_total_area = total_area
    growth_rates.append(growth_rate)

    return frame


```
Here we threshold the image to generate a contrast of active image colors with the black background. It is used to threshold pixel values, essentially keeping this variable depending on the kind of flower used. This function is then called upon each frame of the videos shown earlier to get a binary image upon which we find contours



2. For SAM

```
import cv2
import supervision as sv

image_bgr = cv2.imread(IMAGE_PATH)
image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

sam_result = mask_generator.generate(image_rgb)

mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)

detections = sv.Detections.from_sam(sam_result=sam_result)

annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)

sv.plot_images_grid(
    images=[image_bgr, annotated_image],
    grid_size=(1, 2),
    titles=['source image', 'segmented image']
)
```
Here we load the SAM model, and generate masks to annotate our original image with so we can understand the context of why a certain mask has been generated. 

To conclude, while Segment Anything is very impressive in generating distinctive masks for objects, it requires a lot of time and resources. 
Whereas on a case-by-case basis, we can tweak thresholds and obtain masks that are similar in quality distinguishing from noisy backgrounds by applying a bit of preprocessing. In this short case study we only looked at color thresholding yet achieved masks on a few videos that allowed us to calculate how fast the object was changing/growing. 
